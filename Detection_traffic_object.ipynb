{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "276e95fc",
   "metadata": {},
   "source": [
    "# 신호등 최종 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59441f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "# 🔄 Softmax 함수 정의\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "# 🔹 YOLOv8 모델 로드 (COCO pretrained)\n",
    "yolo_model = YOLO(\"yolov8n.pt\")\n",
    "TARGET_CLASS_ID = 9  # traffic light\n",
    "\n",
    "# 🔹 TFLite CNN 모델 로드 (float32, NCHW: [1, 3, 64, 64])\n",
    "interpreter = tf.lite.Interpreter(model_path=\"traffic_light_classifier_float32.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# 🔹 입력 영상\n",
    "video_path = \"/data/LEE/test1.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 🔹 저장 영상 설정\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(\"traffic_light_result.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "# 🔹 프레임 처리 루프\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 1. YOLO 감지\n",
    "    results = yolo_model(frame)[0]\n",
    "\n",
    "    for box in results.boxes.data:\n",
    "        x1, y1, x2, y2, conf, cls = box.cpu().numpy()\n",
    "        if int(cls) != TARGET_CLASS_ID:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "        crop_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "        if crop_img.size == 0:\n",
    "            continue\n",
    "\n",
    "        # ✅ HSV 기반 필터링\n",
    "        hsv_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)\n",
    "        brightness = np.mean(hsv_img[..., 2])        # 밝기 평균\n",
    "        saturation = np.mean(hsv_img[..., 1])        # 채도 평균\n",
    "        max_brightness = np.max(hsv_img[..., 2])     # 밝기 최댓값\n",
    "\n",
    "        if brightness < 40 or saturation < 50 or max_brightness < 80:\n",
    "            continue  # 공통적으로 너무 어두우면 무시\n",
    "\n",
    "        # ✅ 초록불과 빨간불 색상 비율 검사\n",
    "        green_pixels = np.sum((hsv_img[..., 0] > 40) & (hsv_img[..., 0] < 90) & (hsv_img[..., 1] > 50))\n",
    "        red_pixels = np.sum(((hsv_img[..., 0] < 10) | (hsv_img[..., 0] > 160)) & (hsv_img[..., 1] > 50))\n",
    "\n",
    "        total_pixels = crop_img.shape[0] * crop_img.shape[1]\n",
    "        green_ratio = green_pixels / total_pixels\n",
    "        red_ratio = red_pixels / total_pixels\n",
    "\n",
    "        if green_ratio < 0.05 and red_ratio < 0.05:\n",
    "            continue  # 둘 다 너무 적으면 무시\n",
    "\n",
    "        # 2. CNN 전처리\n",
    "        img = Image.fromarray(cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)).resize((64, 64))\n",
    "        input_data = np.asarray(img, dtype=np.float32) / 255.0\n",
    "        input_data = np.transpose(input_data, (2, 0, 1))\n",
    "        input_data = np.expand_dims(input_data, axis=0)\n",
    "\n",
    "        # 3. 추론\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "        probs = softmax(output)\n",
    "        conf_green, conf_red = float(probs[0]), float(probs[1])\n",
    "\n",
    "        # ✅ 확률 기반 판단 + green 오탐 방지 강화\n",
    "        if conf_green > conf_red and conf_green > 0.8:\n",
    "            if green_ratio < 0.10:  # 🔒 더 엄격한 초록 비중 필터\n",
    "                continue\n",
    "            label = \"green\"\n",
    "            confidence = conf_green\n",
    "        elif conf_red > 0.8:\n",
    "            if red_ratio < 0.05:  # 🔒 빨강도 최소한의 비중은 필요\n",
    "                continue\n",
    "            label = \"red\"\n",
    "            confidence = conf_red\n",
    "        else:\n",
    "            continue  # 확신 부족\n",
    "\n",
    "        # 4. 시각화\n",
    "        color = (0, 255, 0) if label == \"green\" else (0, 0, 255)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        text = f\"{label.upper()} ({confidence:.2f})\"\n",
    "        cv2.putText(frame, text, (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    # 프레임 저장\n",
    "    out.write(frame)\n",
    "\n",
    "# 마무리\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"✅ 결과 저장 완료: traffic_light_result.mp4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5864d1b",
   "metadata": {},
   "source": [
    "# 횡단보도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "867f66bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in /data/yolov8_env/lib/python3.8/site-packages (1.1.58)\n",
      "Requirement already satisfied: requests in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: idna==3.7 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: python-dotenv in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (1.0.1)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (10.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (6.0.2)\n",
      "Requirement already satisfied: pillow-heif>=0.18.0 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (0.18.0)\n",
      "Requirement already satisfied: matplotlib in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (3.7.5)\n",
      "Requirement already satisfied: cycler in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (1.4.7)\n",
      "Requirement already satisfied: python-dateutil in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: six in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (1.24.3)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (2.2.3)\n",
      "Requirement already satisfied: filetype in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: requests-toolbelt in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: certifi in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/yolov8_env/lib/python3.8/site-packages (from requests->roboflow) (3.4.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /data/yolov8_env/lib/python3.8/site-packages (from matplotlib->roboflow) (4.56.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0; python_version < \"3.10\" in /data/yolov8_env/lib/python3.8/site-packages (from matplotlib->roboflow) (6.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /data/yolov8_env/lib/python3.8/site-packages (from matplotlib->roboflow) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /data/yolov8_env/lib/python3.8/site-packages (from matplotlib->roboflow) (3.1.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /data/yolov8_env/lib/python3.8/site-packages (from matplotlib->roboflow) (24.2)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /data/yolov8_env/lib/python3.8/site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib->roboflow) (3.20.2)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Crosswalk-6 to yolov8:: 100%|██████████| 115112/115112 [00:11<00:00, 10318.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Crosswalk-6 in yolov8:: 100%|██████████| 2999/2999 [00:00<00:00, 7544.24it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"ZxSEfCzVHgJMRddrxT0u\")\n",
    "project = rf.workspace(\"tom-lai-8bp7n\").project(\"crosswalk-xlzhu\")\n",
    "version = project.version(6)\n",
    "dataset = version.download(\"yolov8\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d3a93cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 94개의 어두운 이미지가 제거되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "def is_dark(image_path, threshold=50):\n",
    "    img = cv2.imread(image_path)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    v_mean = hsv[..., 2].mean()\n",
    "    return v_mean < threshold\n",
    "\n",
    "# 📁 경로 설정\n",
    "image_dir = \"/data/LEE/Crosswalk-6/train/images\"\n",
    "label_dir = \"/data/LEE/Crosswalk-6/train/labels\"\n",
    "\n",
    "# 📁 제거할 목록 저장\n",
    "remove_list = []\n",
    "\n",
    "for filename in os.listdir(image_dir):\n",
    "    if not filename.endswith(\".jpg\"):\n",
    "        continue\n",
    "    img_path = os.path.join(image_dir, filename)\n",
    "    if is_dark(img_path):\n",
    "        remove_list.append(filename)\n",
    "\n",
    "# 🔥 이미지 + 레이블 같이 제거\n",
    "for fname in remove_list:\n",
    "    img_path = os.path.join(image_dir, fname)\n",
    "    label_path = os.path.join(label_dir, fname.replace(\".jpg\", \".txt\"))\n",
    "    os.remove(img_path)\n",
    "    if os.path.exists(label_path):\n",
    "        os.remove(label_path)\n",
    "\n",
    "print(f\"✅ 총 {len(remove_list)}개의 어두운 이미지가 제거되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38fd6a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in /data/yolov8_env/lib/python3.8/site-packages (1.1.58)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (2.2.3)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (10.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: pillow-heif>=0.18.0 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (0.18.0)\n",
      "Requirement already satisfied: certifi in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (2025.1.31)\n",
      "Requirement already satisfied: six in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: python-dotenv in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (1.0.1)\n",
      "Requirement already satisfied: requests-toolbelt in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: matplotlib in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (3.7.5)\n",
      "Requirement already satisfied: idna==3.7 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: python-dateutil in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (1.24.3)\n",
      "Requirement already satisfied: filetype in /data/yolov8_env/lib/python3.8/site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /data/yolov8_env/lib/python3.8/site-packages (from matplotlib->roboflow) (24.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /data/yolov8_env/lib/python3.8/site-packages (from matplotlib->roboflow) (4.56.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0; python_version < \"3.10\" in /data/yolov8_env/lib/python3.8/site-packages (from matplotlib->roboflow) (6.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /data/yolov8_env/lib/python3.8/site-packages (from matplotlib->roboflow) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /data/yolov8_env/lib/python3.8/site-packages (from matplotlib->roboflow) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/yolov8_env/lib/python3.8/site-packages (from requests->roboflow) (3.4.1)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /data/yolov8_env/lib/python3.8/site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib->roboflow) (3.20.2)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in safeT_Crosswalk-1 to yolov8:: 100%|██████████| 66889/66889 [00:07<00:00, 9191.42it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to safeT_Crosswalk-1 in yolov8:: 100%|██████████| 2440/2440 [00:00<00:00, 8524.48it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"ZxSEfCzVHgJMRddrxT0u\")\n",
    "project = rf.workspace(\"mia-lkjrc\").project(\"safet_crosswalk\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b150ec3d",
   "metadata": {},
   "source": [
    "## 횡단보도 학습(Crosswalk-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b12dcd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.145 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.94 🚀 Python-3.8.10 torch-1.12.1+cu113 CUDA:0 (NVIDIA A100-SXM4-80GB MIG 1g.10gb, 9728MiB)\n",
      "WARNING ⚠️ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/data/LEE/Crosswalk-6/data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/data/LEE/Crosswalk-6, name=crosswalk_train, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/data/LEE/Crosswalk-6/crosswalk_train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /data/LEE/Crosswalk-6/crosswalk_train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 11.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /data/LEE/Crosswalk-6/train/labels... 1191 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1191/1191 [00:00<00:00, 1634.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /data/LEE/Crosswalk-6/train/labels.cache\n",
      "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1290, len(boxes) = 1444. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data/LEE/Crosswalk-6/valid/labels... 210 images, 0 backgrounds, 0 corrupt: 100%|██████████| 210/210 [00:00<00:00, 936.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /data/LEE/Crosswalk-6/valid/labels.cache\n",
      "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 252, len(boxes) = 259. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /data/LEE/Crosswalk-6/crosswalk_train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/data/LEE/Crosswalk-6/crosswalk_train\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      2.13G      1.325      2.135      1.682         16        640: 100%|██████████| 75/75 [00:13<00:00,  5.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.238      0.208      0.154     0.0594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      2.65G      1.319      1.751      1.637         16        640: 100%|██████████| 75/75 [00:11<00:00,  6.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.259      0.317      0.184     0.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      2.65G      1.289      1.544       1.63         22        640: 100%|██████████| 75/75 [00:11<00:00,  6.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.292      0.246      0.161     0.0429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      2.65G      1.308      1.417       1.63         18        640: 100%|██████████| 75/75 [00:11<00:00,  6.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.189      0.355      0.141     0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      2.65G      1.249      1.342      1.572         16        640: 100%|██████████| 75/75 [00:11<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.621      0.506      0.472       0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      2.65G      1.246      1.278      1.557         18        640: 100%|██████████| 75/75 [00:11<00:00,  6.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.641      0.672      0.661      0.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      2.65G      1.188       1.23      1.528         16        640: 100%|██████████| 75/75 [00:11<00:00,  6.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.772      0.629      0.699      0.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      2.65G      1.155      1.163      1.501         19        640: 100%|██████████| 75/75 [00:11<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.634      0.591      0.641      0.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      2.65G      1.162      1.144      1.503         21        640: 100%|██████████| 75/75 [00:11<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.776      0.734      0.773      0.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      2.65G      1.107      1.108      1.463         20        640: 100%|██████████| 75/75 [00:11<00:00,  6.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.824      0.723       0.81      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      2.65G      1.064      1.025      1.427         21        640: 100%|██████████| 75/75 [00:11<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.889      0.741      0.824      0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      2.65G      1.086      1.043      1.448         16        640: 100%|██████████| 75/75 [00:11<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.778       0.73      0.792      0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      2.65G      1.039      1.038       1.42         22        640: 100%|██████████| 75/75 [00:11<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.815      0.801      0.844      0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      2.65G      1.032      1.005      1.419         25        640: 100%|██████████| 75/75 [00:11<00:00,  6.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.827       0.74      0.833      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      2.65G      1.056      1.001      1.423         15        640: 100%|██████████| 75/75 [00:11<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259       0.85      0.776      0.845      0.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      2.65G      1.008     0.9455      1.391         17        640: 100%|██████████| 75/75 [00:11<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.803      0.803      0.852      0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      2.65G     0.9926     0.9353      1.377         16        640: 100%|██████████| 75/75 [00:11<00:00,  6.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.844      0.803      0.862       0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      2.65G     0.9483     0.8918      1.357         15        640: 100%|██████████| 75/75 [00:11<00:00,  6.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.823      0.807      0.858        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      2.65G     0.9737     0.9084      1.362         33        640: 100%|██████████| 75/75 [00:11<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.924      0.747      0.849      0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      2.65G     0.9835      0.916      1.377         27        640: 100%|██████████| 75/75 [00:11<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.837      0.694      0.799      0.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      2.65G     0.9742     0.8951      1.365         17        640: 100%|██████████| 75/75 [00:11<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.843       0.79      0.873      0.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      2.65G     0.9469     0.8746      1.342         21        640: 100%|██████████| 75/75 [00:11<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.872      0.834      0.886      0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      2.65G     0.9314     0.8559      1.338         26        640: 100%|██████████| 75/75 [00:11<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.885      0.833      0.882      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      2.65G      0.934     0.8698      1.339         15        640: 100%|██████████| 75/75 [00:11<00:00,  6.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.881      0.838      0.893      0.659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      2.65G      0.919     0.8274      1.324         14        640: 100%|██████████| 75/75 [00:11<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.856      0.853      0.892      0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      2.65G     0.9207     0.8498       1.32         22        640: 100%|██████████| 75/75 [00:11<00:00,  6.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.831      0.838      0.883       0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      2.65G     0.8803      0.807      1.299         19        640: 100%|██████████| 75/75 [00:11<00:00,  6.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.893      0.839      0.903      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      2.65G     0.8978     0.8045      1.309         14        640: 100%|██████████| 75/75 [00:11<00:00,  6.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259        0.9      0.833      0.896      0.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      2.65G      0.858     0.7959      1.297         16        640: 100%|██████████| 75/75 [00:11<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.908      0.804      0.906      0.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      2.65G     0.9079      0.801       1.32         19        640: 100%|██████████| 75/75 [00:11<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.867      0.803      0.894      0.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      2.65G     0.8615     0.7813      1.287         13        640: 100%|██████████| 75/75 [00:11<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.902       0.83      0.892      0.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      2.65G     0.8639     0.7777      1.283         13        640: 100%|██████████| 75/75 [00:11<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.887      0.848      0.921      0.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      2.65G     0.8759     0.7935      1.291         24        640: 100%|██████████| 75/75 [00:11<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.919      0.861      0.911      0.691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      2.65G     0.8536     0.7638      1.286         15        640: 100%|██████████| 75/75 [00:11<00:00,  6.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.893      0.867      0.923      0.691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      2.65G     0.8863     0.7849      1.285         25        640: 100%|██████████| 75/75 [00:11<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259       0.92      0.884      0.927        0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      2.65G     0.8298     0.7389      1.277         19        640: 100%|██████████| 75/75 [00:11<00:00,  6.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.923      0.835      0.901      0.662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      2.65G     0.8496     0.7306      1.271         18        640: 100%|██████████| 75/75 [00:11<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.874      0.869      0.924      0.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      2.65G     0.8377     0.7434       1.27         20        640: 100%|██████████| 75/75 [00:11<00:00,  6.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.901      0.879      0.938      0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      2.65G     0.8176     0.7325      1.254         22        640: 100%|██████████| 75/75 [00:11<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.915      0.846      0.902      0.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      2.65G     0.8299     0.7305      1.266         21        640: 100%|██████████| 75/75 [00:11<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.891      0.876      0.919      0.681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      2.65G     0.8379     0.7203      1.256         20        640: 100%|██████████| 75/75 [00:11<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.918      0.866      0.909      0.683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      2.65G     0.7983     0.6816      1.243         24        640: 100%|██████████| 75/75 [00:11<00:00,  6.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.952      0.853      0.927      0.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      2.65G      0.817     0.7023      1.266         28        640: 100%|██████████| 75/75 [00:11<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.957      0.857      0.937      0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      2.65G     0.8138     0.7096      1.246         26        640: 100%|██████████| 75/75 [00:11<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.928      0.842      0.917      0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      2.65G     0.7841     0.6648      1.239         21        640: 100%|██████████| 75/75 [00:11<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.937      0.869      0.929      0.713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      2.65G      0.796     0.6832      1.235         20        640: 100%|██████████| 75/75 [00:11<00:00,  6.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.921      0.896      0.949      0.723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      2.65G     0.8071     0.6993      1.242         15        640: 100%|██████████| 75/75 [00:11<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.942      0.849      0.928      0.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      2.65G     0.7779     0.6612      1.223         23        640: 100%|██████████| 75/75 [00:11<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.872       0.89      0.907       0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      2.65G     0.8033     0.6671      1.242         22        640: 100%|██████████| 75/75 [00:11<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.944      0.847      0.925      0.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      2.65G     0.7859     0.6544      1.238         14        640: 100%|██████████| 75/75 [00:11<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259       0.95      0.849      0.928      0.718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      2.65G     0.7552     0.6556      1.215         17        640: 100%|██████████| 75/75 [00:11<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.953      0.852       0.94      0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      2.65G     0.7325      0.648      1.204         16        640: 100%|██████████| 75/75 [00:11<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259       0.93      0.896      0.943      0.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      2.65G     0.7535     0.6317      1.227         17        640: 100%|██████████| 75/75 [00:11<00:00,  6.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259       0.93      0.869      0.929      0.724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      2.65G     0.7688     0.6477      1.222         20        640: 100%|██████████| 75/75 [00:11<00:00,  6.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.915      0.849       0.93      0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      2.65G     0.7405     0.6359      1.208         23        640: 100%|██████████| 75/75 [00:11<00:00,  6.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.921      0.884      0.941      0.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      2.65G     0.7422     0.6359      1.206         25        640: 100%|██████████| 75/75 [00:11<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.966      0.875      0.948      0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      2.65G     0.7519     0.6285      1.202         18        640: 100%|██████████| 75/75 [00:11<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.963      0.896      0.948      0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      2.65G     0.7474     0.6217      1.197         15        640: 100%|██████████| 75/75 [00:11<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.923      0.879      0.931      0.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      2.65G     0.7436     0.6351      1.197         24        640: 100%|██████████| 75/75 [00:11<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.939      0.892      0.943      0.732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      2.65G     0.7234     0.6197      1.198         26        640: 100%|██████████| 75/75 [00:11<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.878      0.915      0.949      0.734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      2.65G      0.715     0.5987      1.182         10        640: 100%|██████████| 75/75 [00:11<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.933      0.884      0.947      0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      2.65G     0.7347      0.621      1.195         25        640: 100%|██████████| 75/75 [00:11<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.931      0.887      0.944       0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      2.65G     0.7272     0.6046      1.194         17        640: 100%|██████████| 75/75 [00:11<00:00,  6.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.946      0.871      0.951      0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      2.65G     0.7049     0.5862      1.179         14        640: 100%|██████████| 75/75 [00:11<00:00,  6.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.913      0.907       0.94      0.738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      2.65G     0.7095     0.5819      1.185         21        640: 100%|██████████| 75/75 [00:11<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.932      0.873       0.95      0.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      2.65G     0.7233     0.5789      1.182         16        640: 100%|██████████| 75/75 [00:11<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.955      0.893      0.956      0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      2.65G     0.7253     0.6096        1.2         20        640: 100%|██████████| 75/75 [00:11<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.949      0.884      0.948      0.742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      2.65G     0.7048     0.5936      1.171         22        640: 100%|██████████| 75/75 [00:11<00:00,  6.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.944      0.906      0.951       0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      2.65G     0.6965     0.5655      1.174         21        640: 100%|██████████| 75/75 [00:11<00:00,  6.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.926      0.919      0.951       0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      2.65G     0.7146     0.5822      1.185         15        640: 100%|██████████| 75/75 [00:11<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.925      0.927      0.944      0.739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      2.65G     0.7131     0.5825      1.179         22        640: 100%|██████████| 75/75 [00:11<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.921      0.911      0.944      0.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      2.65G     0.7045     0.5743      1.167         22        640: 100%|██████████| 75/75 [00:11<00:00,  6.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.939      0.888      0.942      0.743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      2.65G     0.6741     0.5552      1.158         21        640: 100%|██████████| 75/75 [00:11<00:00,  6.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.922      0.907      0.951      0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      2.65G     0.6619     0.5652      1.152         14        640: 100%|██████████| 75/75 [00:11<00:00,  6.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.908      0.911      0.936      0.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      2.65G      0.673     0.5526      1.155         16        640: 100%|██████████| 75/75 [00:11<00:00,  6.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.952        0.9      0.956      0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      2.65G      0.673     0.5383      1.159         18        640: 100%|██████████| 75/75 [00:11<00:00,  6.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.949      0.915      0.958      0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      2.65G     0.6697     0.5485      1.157         19        640: 100%|██████████| 75/75 [00:11<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.958      0.887      0.951      0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      2.65G     0.6653     0.5558      1.156         14        640: 100%|██████████| 75/75 [00:11<00:00,  6.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.941      0.888      0.952      0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      2.65G     0.6514     0.5212      1.146         16        640: 100%|██████████| 75/75 [00:11<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.944      0.907      0.951      0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      2.65G      0.632     0.5081      1.136         23        640: 100%|██████████| 75/75 [00:11<00:00,  6.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.959      0.907      0.956      0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      2.65G      0.643     0.5267       1.14         19        640: 100%|██████████| 75/75 [00:11<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.968      0.896      0.948      0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      2.65G     0.6339     0.5206      1.132         13        640: 100%|██████████| 75/75 [00:11<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.964      0.888      0.945      0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      2.65G     0.6559     0.5299      1.135         22        640: 100%|██████████| 75/75 [00:11<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259       0.92      0.934      0.956      0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      2.65G     0.6439     0.5206      1.137         20        640: 100%|██████████| 75/75 [00:11<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.938      0.934      0.962      0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      2.65G     0.6306     0.5062      1.138         21        640: 100%|██████████| 75/75 [00:11<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.918      0.927      0.959      0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      2.65G     0.6266     0.5039      1.122         19        640: 100%|██████████| 75/75 [00:11<00:00,  6.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.952      0.918      0.958       0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      2.65G     0.6307     0.5162      1.138         17        640: 100%|██████████| 75/75 [00:11<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.944      0.934      0.962      0.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      2.65G     0.6333     0.5077      1.131         19        640: 100%|██████████| 75/75 [00:11<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.947      0.915      0.961       0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      2.65G     0.6237      0.507      1.129         22        640: 100%|██████████| 75/75 [00:11<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.959      0.901      0.962      0.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100      2.65G     0.6449      0.518      1.136         23        640: 100%|██████████| 75/75 [00:11<00:00,  6.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259       0.93      0.925      0.958      0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      2.65G     0.5926     0.4429       1.17          9        640: 100%|██████████| 75/75 [00:11<00:00,  6.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.949      0.903      0.954      0.783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      2.65G     0.5586     0.4076      1.139          8        640: 100%|██████████| 75/75 [00:11<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.955      0.905      0.957      0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      2.65G     0.5575     0.3896      1.142         11        640: 100%|██████████| 75/75 [00:11<00:00,  6.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.951      0.938      0.968      0.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      2.65G     0.5479      0.388      1.119          7        640: 100%|██████████| 75/75 [00:11<00:00,  6.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.971      0.916      0.965      0.798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      2.65G      0.541     0.3754       1.11          7        640: 100%|██████████| 75/75 [00:11<00:00,  6.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259       0.96      0.922       0.96       0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      2.65G     0.5371       0.38      1.113          8        640: 100%|██████████| 75/75 [00:11<00:00,  6.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.959      0.915      0.961       0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100      2.65G     0.5352     0.3817      1.119          7        640: 100%|██████████| 75/75 [00:11<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.968      0.911      0.965      0.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      2.65G     0.5181     0.3769      1.104          9        640: 100%|██████████| 75/75 [00:11<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.968      0.915      0.969      0.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      2.65G     0.5192     0.3692      1.107          7        640: 100%|██████████| 75/75 [00:11<00:00,  6.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.962      0.923      0.967      0.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100      2.65G     0.5254     0.3702      1.105          8        640: 100%|██████████| 75/75 [00:11<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.956      0.931      0.964      0.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 0.353 hours.\n",
      "Optimizer stripped from /data/LEE/Crosswalk-6/crosswalk_train/weights/last.pt, 6.3MB\n",
      "Optimizer stripped from /data/LEE/Crosswalk-6/crosswalk_train/weights/best.pt, 6.3MB\n",
      "\n",
      "Validating /data/LEE/Crosswalk-6/crosswalk_train/weights/best.pt...\n",
      "Ultralytics 8.3.94 🚀 Python-3.8.10 torch-1.12.1+cu113 CUDA:0 (NVIDIA A100-SXM4-80GB MIG 1g.10gb, 9728MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:01<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        210        259      0.966      0.919      0.965      0.797\n",
      "Speed: 0.7ms preprocess, 3.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1m/data/LEE/Crosswalk-6/crosswalk_train\u001b[0m\n",
      "✅ 모델 학습 완료! crosswalk.pt 저장 위치:\n",
      "/data/LEE/Crosswalk-6/crosswalk.pt\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# ✅ 모델 불러오기 (경량 버전)\n",
    "model = YOLO(\"yolov8n.pt\")  # yolov8s.pt 등으로 변경 가능\n",
    "\n",
    "# ✅ 학습 수행\n",
    "model.train(\n",
    "    data=\"/data/LEE/Crosswalk-6/data.yaml\",  # ← 실제 경로에 맞게 수정\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,               # GPU 사양에 맞게 조절\n",
    "    project=\"/data/LEE/Crosswalk-6\",         # 결과 폴더 위치\n",
    "    name=\"crosswalk_train\", # 결과 폴더 이름\n",
    "    exist_ok=True           # 폴더 중복 방지\n",
    ")\n",
    "\n",
    "# ✅ 학습 완료 후 파일 경로\n",
    "best_model_path = \"/data/LEE/Crosswalk-6/crosswalk.pt\"\n",
    "print(f\"✅ 모델 학습 완료! crosswalk.pt 저장 위치:\\n{best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce841c5d",
   "metadata": {},
   "source": [
    "## 횡단보도 출력(/data/LEE/Crosswalk-6/crosswalk_train/weights/best.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cfbee1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 4 crosswalks, 8.7ms\n",
      "Speed: 2.2ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 8.1ms\n",
      "Speed: 1.3ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.2ms\n",
      "Speed: 1.3ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 9.5ms\n",
      "Speed: 1.9ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 12.4ms\n",
      "Speed: 1.5ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.5ms\n",
      "Speed: 1.2ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.9ms\n",
      "Speed: 1.3ms preprocess, 8.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.4ms\n",
      "Speed: 1.3ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.2ms\n",
      "Speed: 1.3ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.6ms\n",
      "Speed: 1.2ms preprocess, 8.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "🎬 추론 완료! 결과 영상 저장됨: result_crosswalk.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ✅ 모델 로드\n",
    "model = YOLO(\"/data/LEE/Crosswalk-6/crosswalk_train/weights/best.pt\")  # ← best.pt 경로 확인\n",
    "\n",
    "# ✅ 영상 경로 설정\n",
    "video_path = \"/data/LEE/test1.mp4\"         # ⬅️ 추론할 영상 경로\n",
    "output_path = \"result_crosswalk.mp4\"  # ⬅️ 출력 영상 경로\n",
    "\n",
    "# ✅ 비디오 읽기\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# ✅ 비디오 저장 객체 초기화\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "# ✅ 프레임별 추론\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # YOLOv8 추론 (이미지 단일 프레임 입력)\n",
    "    results = model(frame)[0]\n",
    "\n",
    "    for box in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, conf, cls = box\n",
    "        if conf < 0.5:\n",
    "            continue\n",
    "\n",
    "        # 바운딩 박스 좌표 정수화\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "\n",
    "        # 바운딩 박스 및 텍스트 표시\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "        label = f\"Crosswalk {conf:.2f}\"\n",
    "        cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "    # 결과 프레임 저장\n",
    "    out.write(frame)\n",
    "\n",
    "# ✅ 마무리\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"🎬 추론 완료! 결과 영상 저장됨:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddab0b7",
   "metadata": {},
   "source": [
    "# 신호등 + 횡단보도(최종)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d394c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 5 cars, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 traffic light, 8.3ms\n",
      "Speed: 1.1ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 traffic light, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 2 traffic lights, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 2 traffic lights, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 2 traffic lights, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 2 traffic lights, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 traffic light, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 2 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 2 traffic lights, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 2 traffic lights, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 2 traffic lights, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 1 traffic light, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 traffic light, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 traffic light, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 traffic light, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 traffic light, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 traffic light, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 3 traffic lights, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 traffic light, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 9 cars, 1 traffic light, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 10 cars, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 traffic light, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 10 cars, 1 truck, 1 traffic light, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 2 traffic lights, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 traffic light, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 traffic light, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 10 cars, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 9 cars, 3 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 10 cars, 1 truck, 1 traffic light, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 9 cars, 1 truck, 2 traffic lights, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 2 trucks, 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 11 cars, 1 truck, 2 traffic lights, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 9 cars, 1 truck, 1 traffic light, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 9 cars, 1 truck, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 truck, 1 traffic light, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 1 traffic light, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 2 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 1 traffic light, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 2 traffic lights, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 1 traffic light, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 2 traffic lights, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 1 traffic light, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 3 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bench, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bench, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 bench, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bench, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bench, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bench, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bench, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 bench, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bench, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bench, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bench, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bench, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 1 bench, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 1 fire hydrant, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 1 fire hydrant, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 1 fire hydrant, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 1 fire hydrant, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 1 fire hydrant, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 1 bench, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 1 parking meter, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 1 fire hydrant, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 1 fire hydrant, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 1 parking meter, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 3 traffic lights, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 4 traffic lights, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 4 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 4 traffic lights, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 4 traffic lights, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 6 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 6 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 6 traffic lights, 1 parking meter, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 6 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 6 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 1 parking meter, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 traffic light, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 traffic light, 8.1ms\n",
      "Speed: 1.3ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 2 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 2 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 2 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 traffic light, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 traffic light, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 2 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 2 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 2 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 2 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 2 traffic lights, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 traffic light, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 traffic light, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 3 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 2 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 2 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 2 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 9 cars, 1 traffic light, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 10 cars, 1 traffic light, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 2 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 2 traffic lights, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 10 cars, 1 truck, 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 2 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 traffic light, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 10 cars, 1 traffic light, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 traffic light, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 9 cars, 3 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 10 cars, 1 truck, 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 9 cars, 1 truck, 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 2 trucks, 1 traffic light, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 11 cars, 1 truck, 2 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 9 cars, 1 truck, 1 traffic light, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 9 cars, 1 truck, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 truck, 1 traffic light, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 2 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 1 traffic light, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 2 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 2 traffic lights, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 2 traffic lights, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 2 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.0ms\n",
      "Speed: 1.3ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.5ms\n",
      "Speed: 1.3ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.7ms\n",
      "Speed: 1.3ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 2 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bench, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bench, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 bench, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bench, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bench, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bench, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bench, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 bench, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bench, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bench, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.3ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bench, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.4ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bench, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 1 bench, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 1 traffic light, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.6ms\n",
      "Speed: 1.4ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 7.3ms\n",
      "Speed: 2.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.3ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 truck, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 cars, 1 truck, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 1 fire hydrant, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 truck, 1 fire hydrant, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 1 fire hydrant, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 1 fire hydrant, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 truck, 1 fire hydrant, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 truck, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.4ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.3ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.4ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.3ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.4ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.3ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.4ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.8ms\n",
      "Speed: 1.3ms preprocess, 6.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 1 bench, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 1 parking meter, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 1 fire hydrant, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 1 fire hydrant, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 1 parking meter, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 4 traffic lights, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 4 traffic lights, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 6 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 6 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 6 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 6 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 1 parking meter, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 6 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.7ms\n",
      "Speed: 1.3ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 1 parking meter, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 1 parking meter, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 1 parking meter, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 traffic light, 1 parking meter, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 1 parking meter, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 traffic lights, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "✅ 최종 결과 저장 완료: final_result2.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "# 🔄 Softmax 함수\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "# ✅ 모델 불러오기\n",
    "traffic_yolo = YOLO(\"yolov8n.pt\")  # 신호등 감지 (COCO pretrained)\n",
    "crosswalk_yolo = YOLO(\"/data/LEE/Crosswalk-6/crosswalk_train/weights/best.pt\")  # 횡단보도 전용 모델\n",
    "TARGET_CLASS_ID = 9  # traffic light 클래스 (COCO 기준)\n",
    "\n",
    "# ✅ TFLite 신호등 색 분류기 로드\n",
    "interpreter = tf.lite.Interpreter(model_path=\"traffic_light_classifier_float32.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# ✅ 입력 영상\n",
    "video_path = \"/data/LEE/test2.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# ✅ 출력 영상 설정\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(\"final_result2.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "# ✅ 프레임 처리 루프\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 1. YOLO로 신호등 감지\n",
    "    results = traffic_yolo(frame)[0]\n",
    "    red_light_detected = False\n",
    "\n",
    "    for box in results.boxes.data:\n",
    "        x1, y1, x2, y2, conf, cls = box.cpu().numpy()\n",
    "        if int(cls) != TARGET_CLASS_ID:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "        crop_img = frame[y1:y2, x1:x2]\n",
    "        if crop_img.size == 0:\n",
    "            continue\n",
    "\n",
    "        # HSV 필터링\n",
    "        hsv_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)\n",
    "        brightness = np.mean(hsv_img[..., 2])\n",
    "        saturation = np.mean(hsv_img[..., 1])\n",
    "        max_brightness = np.max(hsv_img[..., 2])\n",
    "        if brightness < 40 or saturation < 50 or max_brightness < 80:\n",
    "            continue\n",
    "\n",
    "        # 색상 비율\n",
    "        green_pixels = np.sum((hsv_img[..., 0] > 40) & (hsv_img[..., 0] < 90) & (hsv_img[..., 1] > 50))\n",
    "        red_pixels = np.sum(((hsv_img[..., 0] < 10) | (hsv_img[..., 0] > 160)) & (hsv_img[..., 1] > 50))\n",
    "        total_pixels = crop_img.shape[0] * crop_img.shape[1]\n",
    "        green_ratio = green_pixels / total_pixels\n",
    "        red_ratio = red_pixels / total_pixels\n",
    "        if green_ratio < 0.05 and red_ratio < 0.05:\n",
    "            continue\n",
    "\n",
    "        # CNN 분류기 전처리 및 추론\n",
    "        img = Image.fromarray(cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)).resize((64, 64))\n",
    "        input_data = np.asarray(img, dtype=np.float32) / 255.0\n",
    "        input_data = np.transpose(input_data, (2, 0, 1))\n",
    "        input_data = np.expand_dims(input_data, axis=0)\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "        probs = softmax(output)\n",
    "        conf_green, conf_red = float(probs[0]), float(probs[1])\n",
    "\n",
    "        # 색상 판별\n",
    "        if conf_green > conf_red and conf_green > 0.8:\n",
    "            if green_ratio < 0.10:\n",
    "                continue\n",
    "            label = \"green\"\n",
    "            confidence = conf_green\n",
    "        elif conf_red > 0.8:\n",
    "            if red_ratio < 0.05:\n",
    "                continue\n",
    "            label = \"red\"\n",
    "            confidence = conf_red\n",
    "            red_light_detected = True\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # 신호등 시각화\n",
    "        color = (0, 255, 0) if label == \"green\" else (0, 0, 255)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        text = f\"{label.upper()} ({confidence:.2f})\"\n",
    "        cv2.putText(frame, text, (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    # 2. 횡단보도는 항상 감지\n",
    "    import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "# 🔄 Softmax 함수\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "# ✅ 모델 불러오기\n",
    "traffic_yolo = YOLO(\"yolov8n.pt\")  # 신호등 감지 (COCO pretrained)\n",
    "crosswalk_yolo = YOLO(\"/data/LEE/Crosswalk-6/crosswalk_train/weights/best.pt\")  # 횡단보도 전용 모델\n",
    "TARGET_CLASS_ID = 9  # traffic light 클래스 (COCO 기준)\n",
    "\n",
    "# ✅ TFLite 신호등 색 분류기 로드\n",
    "interpreter = tf.lite.Interpreter(model_path=\"traffic_light_classifier_float32.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# ✅ 입력 영상\n",
    "video_path = \"/data/LEE/test2.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# ✅ 출력 영상 설정\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(\"final_result2.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "# ✅ 프레임 처리 루프\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 1. YOLO로 신호등 감지\n",
    "    results = traffic_yolo(frame)[0]\n",
    "    red_light_detected = False\n",
    "\n",
    "    for box in results.boxes.data:\n",
    "        x1, y1, x2, y2, conf, cls = box.cpu().numpy()\n",
    "        if int(cls) != TARGET_CLASS_ID:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "        crop_img = frame[y1:y2, x1:x2]\n",
    "        if crop_img.size == 0:\n",
    "            continue\n",
    "\n",
    "        # HSV 필터링\n",
    "        hsv_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)\n",
    "        brightness = np.mean(hsv_img[..., 2])\n",
    "        saturation = np.mean(hsv_img[..., 1])\n",
    "        max_brightness = np.max(hsv_img[..., 2])\n",
    "        if brightness < 40 or saturation < 50 or max_brightness < 80:\n",
    "            continue\n",
    "\n",
    "        # 색상 비율\n",
    "        green_pixels = np.sum((hsv_img[..., 0] > 40) & (hsv_img[..., 0] < 90) & (hsv_img[..., 1] > 50))\n",
    "        red_pixels = np.sum(((hsv_img[..., 0] < 10) | (hsv_img[..., 0] > 160)) & (hsv_img[..., 1] > 50))\n",
    "        total_pixels = crop_img.shape[0] * crop_img.shape[1]\n",
    "        green_ratio = green_pixels / total_pixels\n",
    "        red_ratio = red_pixels / total_pixels\n",
    "        if green_ratio < 0.05 and red_ratio < 0.05:\n",
    "            continue\n",
    "\n",
    "        # CNN 분류기 전처리 및 추론\n",
    "        img = Image.fromarray(cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)).resize((64, 64))\n",
    "        input_data = np.asarray(img, dtype=np.float32) / 255.0\n",
    "        input_data = np.transpose(input_data, (2, 0, 1))\n",
    "        input_data = np.expand_dims(input_data, axis=0)\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "        probs = softmax(output)\n",
    "        conf_green, conf_red = float(probs[0]), float(probs[1])\n",
    "\n",
    "        # 색상 판별\n",
    "        if conf_green > conf_red and conf_green > 0.8:\n",
    "            if green_ratio < 0.10:\n",
    "                continue\n",
    "            label = \"green\"\n",
    "            confidence = conf_green\n",
    "        elif conf_red > 0.8:\n",
    "            if red_ratio < 0.05:\n",
    "                continue\n",
    "            label = \"red\"\n",
    "            confidence = conf_red\n",
    "            red_light_detected = True\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # 신호등 시각화\n",
    "        color = (0, 255, 0) if label == \"green\" else (0, 0, 255)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        text = f\"{label.upper()} ({confidence:.2f})\"\n",
    "        cv2.putText(frame, text, (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    # 2. 횡단보도는 항상 감지\n",
    "    cross_results = crosswalk_yolo(frame)[0]\n",
    "    for cbox in cross_results.boxes.data.tolist():\n",
    "        cx1, cy1, cx2, cy2, cconf, ccls = cbox\n",
    "        if cconf < 0.5:\n",
    "            continue\n",
    "        cx1, cy1, cx2, cy2 = map(int, [cx1, cy1, cx2, cy2])\n",
    "        cv2.rectangle(frame, (cx1, cy1), (cx2, cy2), (255, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Crosswalk ({cconf:.2f})\", (cx1, cy1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "\n",
    "\n",
    "    # 프레임 저장\n",
    "    out.write(frame)\n",
    "    \n",
    "\n",
    "# 마무리\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"✅ 최종 결과 저장 완료: final_result2.mp4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1067d88d",
   "metadata": {},
   "source": [
    "# + 가로등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c85a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 6 traffic lights, 7.8ms\n",
      "Speed: 2.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.5ms\n",
      "Speed: 1.3ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 2 buss, 5 traffic lights, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 2 buss, 5 traffic lights, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 2 buss, 4 traffic lights, 8.2ms\n",
      "Speed: 1.1ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 4 traffic lights, 8.2ms\n",
      "Speed: 1.1ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 4 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 2 buss, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 4 traffic lights, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 4 traffic lights, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 5 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 4 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 4 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 truck, 3 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 truck, 3 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 truck, 3 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 1 truck, 3 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 3 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 truck, 3 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 truck, 3 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 3 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 truck, 3 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 truck, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 truck, 3 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 truck, 4 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 1 truck, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 1 truck, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 truck, 3 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 truck, 3 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 truck, 3 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 crosswalks, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 train, 1 truck, 3 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 crosswalks, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 truck, 4 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 truck, 3 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 truck, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 truck, 3 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 truck, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 4 traffic lights, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 3 traffic lights, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 truck, 4 traffic lights, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 6 traffic lights, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 6 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 6 traffic lights, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 6 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 6 traffic lights, 8.2ms\n",
      "Speed: 1.1ms preprocess, 8.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 6 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 6 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 1 truck, 6 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 4 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 3 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 6 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.7ms\n",
      "Speed: 1.3ms preprocess, 7.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 8 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 7 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 7 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 9 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 7 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 6 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 6 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 2 buss, 6 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 2 buss, 7 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 2 buss, 8 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 2 buss, 7 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 6 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 2 buss, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 1 train, 6 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 2 buss, 1 train, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 1 train, 4 traffic lights, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 1 truck, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 1 truck, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 car, 1 bus, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 1 bus, 3 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 2 buss, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 1 train, 4 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 1 bus, 1 train, 4 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 1 bus, 1 truck, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 2 buss, 1 truck, 5 traffic lights, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 1 truck, 4 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 1 truck, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 1 bus, 1 truck, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 1 bus, 1 truck, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 1 bus, 4 traffic lights, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 1 bus, 1 truck, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 1 truck, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 1 truck, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 1 truck, 4 traffic lights, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 1 bus, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 4 traffic lights, 8.3ms\n",
      "Speed: 1.1ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 4 traffic lights, 8.2ms\n",
      "Speed: 1.1ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 4 traffic lights, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 8.2ms\n",
      "Speed: 1.3ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 3 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 6 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 4 traffic lights, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 3 traffic lights, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 6 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 6 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 6 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 5 traffic lights, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 6 traffic lights, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 5 traffic lights, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 5 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 bus, 5 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 4 traffic lights, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 street_poles, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 4 traffic lights, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 crosswalks, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 street_pole, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "✅ 최종 결과 저장 완료: final_result_with_streetlamp.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "# 🔄 Softmax 함수\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "# ✅ 모델 로딩\n",
    "traffic_yolo = YOLO(\"yolov8n.pt\")  # 신호등 감지 (COCO)\n",
    "crosswalk_yolo = YOLO(\"/data/LEE/Crosswalk-6/crosswalk_train/weights/best.pt\")  # 횡단보도\n",
    "lamp_yolo = YOLO(\"/data/LEE/obstacle_detection_epoch15.pt\")  # 가로등 감지 모델 (사용자 준비 필요)\n",
    "TARGET_CLASS_ID = 9  # traffic light 클래스 (COCO 기준)\n",
    "\n",
    "# ✅ TFLite 신호등 색 분류기\n",
    "interpreter = tf.lite.Interpreter(model_path=\"traffic_light_classifier_float32.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# ✅ 영상 설정\n",
    "video_path = \"/data/LEE/test1.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "out = cv2.VideoWriter(\"final_result_with_streetlamp.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "# ✅ 프레임 루프\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    red_light_detected = False\n",
    "    results = traffic_yolo(frame)[0]\n",
    "\n",
    "    # 1. 신호등 감지 + 색 분류\n",
    "    for box in results.boxes.data:\n",
    "        x1, y1, x2, y2, conf, cls = box.cpu().numpy()\n",
    "        if int(cls) != TARGET_CLASS_ID:\n",
    "            continue\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "        crop_img = frame[y1:y2, x1:x2]\n",
    "        if crop_img.size == 0:\n",
    "            continue\n",
    "\n",
    "        hsv_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)\n",
    "        brightness = np.mean(hsv_img[..., 2])\n",
    "        saturation = np.mean(hsv_img[..., 1])\n",
    "        max_brightness = np.max(hsv_img[..., 2])\n",
    "        if brightness < 40 or saturation < 50 or max_brightness < 80:\n",
    "            continue\n",
    "\n",
    "        green_pixels = np.sum((hsv_img[..., 0] > 40) & (hsv_img[..., 0] < 90) & (hsv_img[..., 1] > 50))\n",
    "        red_pixels = np.sum(((hsv_img[..., 0] < 10) | (hsv_img[..., 0] > 160)) & (hsv_img[..., 1] > 50))\n",
    "        total_pixels = crop_img.shape[0] * crop_img.shape[1]\n",
    "        green_ratio = green_pixels / total_pixels\n",
    "        red_ratio = red_pixels / total_pixels\n",
    "        if green_ratio < 0.05 and red_ratio < 0.05:\n",
    "            continue\n",
    "\n",
    "        img = Image.fromarray(cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)).resize((64, 64))\n",
    "        input_data = np.asarray(img, dtype=np.float32) / 255.0\n",
    "        input_data = np.transpose(input_data, (2, 0, 1))\n",
    "        input_data = np.expand_dims(input_data, axis=0)\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "        probs = softmax(output)\n",
    "        conf_green, conf_red = float(probs[0]), float(probs[1])\n",
    "\n",
    "        if conf_green > conf_red and conf_green > 0.8:\n",
    "            if green_ratio < 0.10: continue\n",
    "            label, color, confidence = \"green\", (0, 255, 0), conf_green\n",
    "        elif conf_red > 0.8:\n",
    "            if red_ratio < 0.05: continue\n",
    "            label, color, confidence = \"red\", (0, 0, 255), conf_red\n",
    "            red_light_detected = True\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(frame, f\"{label.upper()} ({confidence:.2f})\", (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    # 2. 횡단보도 감지\n",
    "    cross_results = crosswalk_yolo(frame)[0]\n",
    "    for cbox in cross_results.boxes.data.tolist():\n",
    "        cx1, cy1, cx2, cy2, cconf, ccls = cbox\n",
    "        if cconf < 0.5: continue\n",
    "        cx1, cy1, cx2, cy2 = map(int, [cx1, cy1, cx2, cy2])\n",
    "        cv2.rectangle(frame, (cx1, cy1), (cx2, cy2), (255, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Crosswalk ({cconf:.2f})\", (cx1, cy1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "\n",
    "    # 3. 가로등 감지\n",
    "    lamp_results = lamp_yolo(frame)[0]\n",
    "    for lbox in lamp_results.boxes.data.tolist():\n",
    "        lx1, ly1, lx2, ly2, lconf, lcls = lbox\n",
    "        if lconf < 0.5: continue\n",
    "        lx1, ly1, lx2, ly2 = map(int, [lx1, ly1, lx2, ly2])\n",
    "        cv2.rectangle(frame, (lx1, ly1), (lx2, ly2), (255, 0, 255), 2)\n",
    "        cv2.putText(frame, f\"StreetLamp ({lconf:.2f})\", (lx1, ly1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)\n",
    "\n",
    "    # 프레임 저장\n",
    "    out.write(frame)\n",
    "\n",
    "# ✅ 마무리\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"✅ 최종 결과 저장 완료: final_result_with_streetlamp.mp4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af96259d",
   "metadata": {},
   "source": [
    "# 모든 객체 감지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed204fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 (no detections), 20.4ms\n",
      "Speed: 2.1ms preprocess, 20.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 19.8ms\n",
      "Speed: 1.1ms preprocess, 19.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 19.0ms\n",
      "Speed: 1.1ms preprocess, 19.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 18.7ms\n",
      "Speed: 1.1ms preprocess, 18.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 16.0ms\n",
      "Speed: 1.1ms preprocess, 16.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 16.0ms\n",
      "Speed: 1.1ms preprocess, 16.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 16.0ms\n",
      "Speed: 1.1ms preprocess, 16.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 16.0ms\n",
      "Speed: 1.1ms preprocess, 16.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 16.0ms\n",
      "Speed: 1.1ms preprocess, 16.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 16.0ms\n",
      "Speed: 1.1ms preprocess, 16.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 16.0ms\n",
      "Speed: 1.1ms preprocess, 16.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 16.0ms\n",
      "Speed: 1.1ms preprocess, 16.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.8ms\n",
      "Speed: 1.1ms preprocess, 15.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.9ms\n",
      "Speed: 1.2ms preprocess, 15.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 8.3ms\n",
      "Speed: 1.3ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.9ms\n",
      "Speed: 1.1ms preprocess, 15.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.9ms\n",
      "Speed: 1.1ms preprocess, 15.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.4ms\n",
      "Speed: 1.1ms preprocess, 15.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.4ms\n",
      "Speed: 1.1ms preprocess, 15.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.5ms\n",
      "Speed: 1.1ms preprocess, 15.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.4ms\n",
      "Speed: 1.2ms preprocess, 15.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.4ms\n",
      "Speed: 1.1ms preprocess, 15.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.4ms\n",
      "Speed: 1.1ms preprocess, 15.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.4ms\n",
      "Speed: 1.1ms preprocess, 15.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.4ms\n",
      "Speed: 1.1ms preprocess, 14.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.4ms\n",
      "Speed: 1.1ms preprocess, 14.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.4ms\n",
      "Speed: 1.1ms preprocess, 14.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.8ms\n",
      "Speed: 0.9ms preprocess, 6.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.3ms\n",
      "Speed: 1.2ms preprocess, 14.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.4ms\n",
      "Speed: 1.2ms preprocess, 14.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 8.6ms\n",
      "Speed: 1.2ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.3ms\n",
      "Speed: 1.3ms preprocess, 14.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 0.9ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 14.4ms\n",
      "Speed: 1.1ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 0.9ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 15.3ms\n",
      "Speed: 1.1ms preprocess, 15.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.3ms\n",
      "Speed: 1.5ms preprocess, 15.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.8ms\n",
      "Speed: 1.2ms preprocess, 14.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.3ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 stop sign, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 1 bus, 14.8ms\n",
      "Speed: 1.2ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 bus, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 cars, 1 bus, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.7ms\n",
      "Speed: 1.3ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 car, 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 15.1ms\n",
      "Speed: 1.2ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 14.3ms\n",
      "Speed: 1.2ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 truck, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 1 truck, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 truck, 14.2ms\n",
      "Speed: 1.1ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 1 bus, 1 truck, 14.3ms\n",
      "Speed: 1.2ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 14.2ms\n",
      "Speed: 1.2ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 truck, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 14.2ms\n",
      "Speed: 1.1ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 14.5ms\n",
      "Speed: 1.1ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 14.8ms\n",
      "Speed: 1.2ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 14.7ms\n",
      "Speed: 1.1ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 14.7ms\n",
      "Speed: 1.1ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bicycle, 1 bus, 14.9ms\n",
      "Speed: 1.2ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 14.9ms\n",
      "Speed: 1.2ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 bicycles, 1 bus, 14.9ms\n",
      "Speed: 1.3ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 14.9ms\n",
      "Speed: 1.2ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bus, 15.1ms\n",
      "Speed: 1.2ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bicycle, 1 bus, 15.2ms\n",
      "Speed: 1.1ms preprocess, 15.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 truck, 15.3ms\n",
      "Speed: 1.1ms preprocess, 15.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bus, 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bus, 15.0ms\n",
      "Speed: 1.1ms preprocess, 15.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 truck, 15.1ms\n",
      "Speed: 1.2ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 15.1ms\n",
      "Speed: 1.2ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 car, 1 bus, 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 car, 1 bus, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 14.8ms\n",
      "Speed: 1.2ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 car, 1 bus, 14.8ms\n",
      "Speed: 1.2ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 car, 14.8ms\n",
      "Speed: 1.2ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 car, 1 bus, 14.8ms\n",
      "Speed: 1.2ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 car, 14.8ms\n",
      "Speed: 1.2ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 1 bus, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.4ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 buss, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 14.3ms\n",
      "Speed: 1.2ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 14.3ms\n",
      "Speed: 1.2ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 14.3ms\n",
      "Speed: 1.3ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 14.6ms\n",
      "Speed: 1.1ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 14.9ms\n",
      "Speed: 1.2ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Braille, 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 14.9ms\n",
      "Speed: 1.2ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 15.3ms\n",
      "Speed: 1.1ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f14df15e070>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/yolov8_env/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 15.6ms\n",
      "Speed: 1.1ms preprocess, 15.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bicycle, 2 buss, 16.2ms\n",
      "Speed: 1.2ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 motorcycle, 1 bus, 1 truck, 16.3ms\n",
      "Speed: 1.2ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Braille, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 1 truck, 16.2ms\n",
      "Speed: 1.1ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Braille, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Braille, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Braille, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Braille, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Braille, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 14.8ms\n",
      "Speed: 1.2ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Braille, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Braille, 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Braille, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bus, 14.8ms\n",
      "Speed: 1.2ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 14.6ms\n",
      "Speed: 1.1ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bus, 1 truck, 14.7ms\n",
      "Speed: 1.1ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 truck, 14.7ms\n",
      "Speed: 1.1ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 truck, 14.7ms\n",
      "Speed: 1.1ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 truck, 14.7ms\n",
      "Speed: 1.2ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 14.7ms\n",
      "Speed: 1.2ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 14.7ms\n",
      "Speed: 1.1ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 14.7ms\n",
      "Speed: 1.2ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 14.7ms\n",
      "Speed: 1.1ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 motorcycle, 1 bus, 14.7ms\n",
      "Speed: 1.2ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 buss, 14.7ms\n",
      "Speed: 1.1ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bus, 14.7ms\n",
      "Speed: 1.1ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.5ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 15.3ms\n",
      "Speed: 1.1ms preprocess, 15.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 motorcycle, 2 buss, 15.8ms\n",
      "Speed: 1.1ms preprocess, 15.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 buss, 15.8ms\n",
      "Speed: 1.1ms preprocess, 15.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 motorcycle, 16.0ms\n",
      "Speed: 1.1ms preprocess, 16.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 motorcycle, 16.0ms\n",
      "Speed: 1.1ms preprocess, 16.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Bicycle, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Bicycle, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 16.0ms\n",
      "Speed: 1.1ms preprocess, 16.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 16.3ms\n",
      "Speed: 1.1ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 motorcycle, 16.2ms\n",
      "Speed: 1.2ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 motorcycle, 1 bus, 15.6ms\n",
      "Speed: 1.1ms preprocess, 15.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 motorcycle, 15.6ms\n",
      "Speed: 1.1ms preprocess, 15.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 15.6ms\n",
      "Speed: 1.2ms preprocess, 15.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 bicycles, 1 bus, 15.6ms\n",
      "Speed: 1.1ms preprocess, 15.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bus, 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 motorcycle, 1 bus, 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 motorcycle, 1 bus, 14.9ms\n",
      "Speed: 1.2ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bicycle, 1 bus, 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bicycle, 1 bus, 14.7ms\n",
      "Speed: 1.1ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 14.7ms\n",
      "Speed: 1.1ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 14.7ms\n",
      "Speed: 1.2ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.4ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 14.7ms\n",
      "Speed: 1.2ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 14.5ms\n",
      "Speed: 1.1ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 bicycles, 14.5ms\n",
      "Speed: 1.1ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 bicycles, 14.5ms\n",
      "Speed: 1.2ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 bicycles, 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bicycle, 1 car, 14.6ms\n",
      "Speed: 1.2ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bicycle, 1 car, 14.6ms\n",
      "Speed: 1.1ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bicycle, 1 car, 14.6ms\n",
      "Speed: 1.2ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bicycle, 14.6ms\n",
      "Speed: 1.1ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 persons, 1 bicycle, 14.6ms\n",
      "Speed: 1.1ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bicycle, 14.6ms\n",
      "Speed: 1.2ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 bicycle, 14.6ms\n",
      "Speed: 1.1ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 14.6ms\n",
      "Speed: 1.1ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 bicycle, 14.9ms\n",
      "Speed: 1.1ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 bicycles, 14.9ms\n",
      "Speed: 1.2ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bicycle, 14.9ms\n",
      "Speed: 1.4ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.6ms\n",
      "Speed: 1.3ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 bicycles, 15.1ms\n",
      "Speed: 1.2ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 car, 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 15.1ms\n",
      "Speed: 1.2ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bus, 15.2ms\n",
      "Speed: 1.1ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 truck, 15.4ms\n",
      "Speed: 1.2ms preprocess, 15.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 truck, 15.4ms\n",
      "Speed: 1.1ms preprocess, 15.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 bicycle, 15.1ms\n",
      "Speed: 1.2ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.9ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 1 bicycle, 1 bus, 1 truck, 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.3ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 15.1ms\n",
      "Speed: 1.1ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 15.1ms\n",
      "Speed: 1.2ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bicycle, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 14.8ms\n",
      "Speed: 1.2ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 persons, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 14.6ms\n",
      "Speed: 1.1ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 14.6ms\n",
      "Speed: 1.1ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 14.6ms\n",
      "Speed: 1.1ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 14.6ms\n",
      "Speed: 1.2ms preprocess, 14.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 14.6ms\n",
      "Speed: 1.2ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 truck, 14.6ms\n",
      "Speed: 1.3ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 14.6ms\n",
      "Speed: 1.1ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 14.6ms\n",
      "Speed: 1.2ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 car, 14.6ms\n",
      "Speed: 1.2ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 14.6ms\n",
      "Speed: 1.2ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 14.6ms\n",
      "Speed: 1.2ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 14.6ms\n",
      "Speed: 1.1ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 persons, 14.6ms\n",
      "Speed: 1.1ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 14.8ms\n",
      "Speed: 1.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 14.8ms\n",
      "Speed: 1.2ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 crosswalks, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 14.3ms\n",
      "Speed: 1.2ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 14.4ms\n",
      "Speed: 1.1ms preprocess, 14.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 14.4ms\n",
      "Speed: 1.1ms preprocess, 14.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 14.3ms\n",
      "Speed: 1.3ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 14.2ms\n",
      "Speed: 1.1ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 14.2ms\n",
      "Speed: 1.2ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bicycle, 14.2ms\n",
      "Speed: 1.1ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 1 bicycle, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 14.2ms\n",
      "Speed: 1.1ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 bicycle, 14.3ms\n",
      "Speed: 1.1ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 14.2ms\n",
      "Speed: 1.1ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 14.2ms\n",
      "Speed: 1.2ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 crosswalk, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 119\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# 4. 자전거 감지 (COCO 모델 사용)\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# 4. 자전거 감지 (사용자 커스텀 모델 사용, 클래스 번호 1번만 감지)\u001b[39;00m\n\u001b[1;32m    117\u001b[0m bike_yolo \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/LEE/bike-and-braille-3/bicycle_train/weights/best.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 119\u001b[0m bike_results \u001b[38;5;241m=\u001b[39m \u001b[43mbike_yolo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# ✅ bike_yolo는 사용자 학습된 YOLO 객체여야 함\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bike_results\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtolist():\n\u001b[1;32m    122\u001b[0m     bx1, by1, bx2, by2, bconf, bcls \u001b[38;5;241m=\u001b[39m bbox\n",
      "File \u001b[0;32m/data/yolov8_env/lib/python3.8/site-packages/ultralytics/engine/model.py:182\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    155\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image\u001b[38;5;241m.\u001b[39mImage, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    156\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/yolov8_env/lib/python3.8/site-packages/ultralytics/engine/model.py:543\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor \u001b[38;5;241m=\u001b[39m (predictor \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smart_load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictor\u001b[39m\u001b[38;5;124m\"\u001b[39m))(overrides\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[0;32m--> 543\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_cli\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# only update args if predictor is already setup\u001b[39;00m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m get_cfg(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39margs, args)\n",
      "File \u001b[0;32m/data/yolov8_env/lib/python3.8/site-packages/ultralytics/engine/predictor.py:378\u001b[0m, in \u001b[0;36mBasePredictor.setup_model\u001b[0;34m(self, model, verbose)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msetup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    Initialize YOLO model with given parameters and set it to evaluation mode.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;124;03m        verbose (bool): Whether to print verbose output.\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mAutoBackend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselect_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhalf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice  \u001b[38;5;66;03m# update device\u001b[39;00m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mhalf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfp16  \u001b[38;5;66;03m# update half\u001b[39;00m\n",
      "File \u001b[0;32m/data/yolov8_env/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/yolov8_env/lib/python3.8/site-packages/ultralytics/nn/autobackend.py:163\u001b[0m, in \u001b[0;36mAutoBackend.__init__\u001b[0;34m(self, weights, device, dnn, data, fp16, batch, fuse, verbose)\u001b[0m\n\u001b[1;32m    161\u001b[0m model \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fuse:\n\u001b[0;32m--> 163\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfuse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkpt_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    165\u001b[0m     kpt_shape \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mkpt_shape  \u001b[38;5;66;03m# pose-only\u001b[39;00m\n",
      "File \u001b[0;32m/data/yolov8_env/lib/python3.8/site-packages/ultralytics/nn/tasks.py:205\u001b[0m, in \u001b[0;36mBaseModel.fuse\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, Conv2):\n\u001b[1;32m    204\u001b[0m     m\u001b[38;5;241m.\u001b[39mfuse_convs()\n\u001b[0;32m--> 205\u001b[0m m\u001b[38;5;241m.\u001b[39mconv \u001b[38;5;241m=\u001b[39m \u001b[43mfuse_conv_and_bn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# update conv\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mdelattr\u001b[39m(m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbn\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# remove batchnorm\u001b[39;00m\n\u001b[1;32m    207\u001b[0m m\u001b[38;5;241m.\u001b[39mforward \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mforward_fuse  \u001b[38;5;66;03m# update forward\u001b[39;00m\n",
      "File \u001b[0;32m/data/yolov8_env/lib/python3.8/site-packages/ultralytics/utils/torch_utils.py:243\u001b[0m, in \u001b[0;36mfuse_conv_and_bn\u001b[0;34m(conv, bn)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfuse_conv_and_bn\u001b[39m(conv, bn):\n\u001b[1;32m    241\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fuse Conv2d() and BatchNorm2d() layers https://tehnokv.com/posts/fusing-batchnorm-and-conv/.\"\"\"\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     fusedconv \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 243\u001b[0m         \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;241m.\u001b[39mto(conv\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m# Prepare filters\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     w_conv \u001b[38;5;241m=\u001b[39m conv\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mview(conv\u001b[38;5;241m.\u001b[39mout_channels, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/data/yolov8_env/lib/python3.8/site-packages/torch/nn/modules/conv.py:444\u001b[0m, in \u001b[0;36mConv2d.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    442\u001b[0m padding_ \u001b[38;5;241m=\u001b[39m padding \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(padding, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m _pair(padding)\n\u001b[1;32m    443\u001b[0m dilation_ \u001b[38;5;241m=\u001b[39m _pair(dilation)\n\u001b[0;32m--> 444\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mConv2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/yolov8_env/lib/python3.8/site-packages/torch/nn/modules/conv.py:109\u001b[0m, in \u001b[0;36m_ConvNd.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_padding \u001b[38;5;241m=\u001b[39m output_padding\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups \u001b[38;5;241m=\u001b[39m groups\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_mode\u001b[49m \u001b[38;5;241m=\u001b[39m padding_mode\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# `_reversed_padding_repeated_twice` is the padding to be passed to\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# `F.pad` if needed (e.g., for non-zero padding types that are\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# implemented as two ops: padding + conv). `F.pad` accepts paddings in\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# reverse order than the dimension.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/data/yolov8_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1219\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1217\u001b[0m                 d\u001b[38;5;241m.\u001b[39mdiscard(name)\n\u001b[0;32m-> 1219\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Parameter):\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "# 🔄 Softmax 함수\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "# ✅ 모델 로딩\n",
    "traffic_yolo = YOLO(\"yolov8m.pt\")  # 신호등 감지 (COCO)\n",
    "crosswalk_yolo = YOLO(\"/data/LEE/Crosswalk-6/crosswalk_train/weights/best.pt\")  # 횡단보도\n",
    "lamp_yolo = YOLO(\"/data/LEE/obstacle_detection_epoch15.pt\")  # 가로등 감지 모델 (사용자 준비 필요)\n",
    "TARGET_CLASS_ID = 9  # traffic light 클래스 (COCO 기준)\n",
    "\n",
    "# ✅ TFLite 신호등 색 분류기\n",
    "interpreter = tf.lite.Interpreter(model_path=\"traffic_light_classifier_float32.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# ✅ 영상 설정\n",
    "video_path = \"/data/LEE/2.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "out = cv2.VideoWriter(\"2_final.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "# ✅ 프레임 루프\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    red_light_detected = False\n",
    "    results = traffic_yolo(frame)[0]\n",
    "\n",
    "    # 1. 신호등 감지 + 색 분류\n",
    "    for box in results.boxes.data:\n",
    "        x1, y1, x2, y2, conf, cls = box.cpu().numpy()\n",
    "        if int(cls) != TARGET_CLASS_ID:\n",
    "            continue\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "        crop_img = frame[y1:y2, x1:x2]\n",
    "        if crop_img.size == 0:\n",
    "            continue\n",
    "\n",
    "        hsv_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)\n",
    "        brightness = np.mean(hsv_img[..., 2])\n",
    "        saturation = np.mean(hsv_img[..., 1])\n",
    "        max_brightness = np.max(hsv_img[..., 2])\n",
    "        if brightness < 40 or saturation < 50 or max_brightness < 80:\n",
    "            continue\n",
    "\n",
    "        green_pixels = np.sum((hsv_img[..., 0] > 40) & (hsv_img[..., 0] < 90) & (hsv_img[..., 1] > 50))\n",
    "        red_pixels = np.sum(((hsv_img[..., 0] < 10) | (hsv_img[..., 0] > 160)) & (hsv_img[..., 1] > 50))\n",
    "        total_pixels = crop_img.shape[0] * crop_img.shape[1]\n",
    "        green_ratio = green_pixels / total_pixels\n",
    "        red_ratio = red_pixels / total_pixels\n",
    "        if green_ratio < 0.05 and red_ratio < 0.05:\n",
    "            continue\n",
    "\n",
    "        img = Image.fromarray(cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)).resize((64, 64))\n",
    "        input_data = np.asarray(img, dtype=np.float32) / 255.0\n",
    "        input_data = np.transpose(input_data, (2, 0, 1))\n",
    "        input_data = np.expand_dims(input_data, axis=0)\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "        probs = softmax(output)\n",
    "        conf_green, conf_red = float(probs[0]), float(probs[1])\n",
    "\n",
    "        if conf_green > conf_red and conf_green > 0.8:\n",
    "            if green_ratio < 0.10: continue\n",
    "            label, color, confidence = \"green\", (0, 255, 0), conf_green\n",
    "        elif conf_red > 0.8:\n",
    "            if red_ratio < 0.05: continue\n",
    "            label, color, confidence = \"red\", (0, 0, 255), conf_red\n",
    "            red_light_detected = True\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(frame, f\"{label.upper()} ({confidence:.2f})\", (x1, y1 - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    # 2. 횡단보도 감지\n",
    "    cross_results = crosswalk_yolo(frame)[0]\n",
    "    for cbox in cross_results.boxes.data.tolist():\n",
    "        cx1, cy1, cx2, cy2, cconf, ccls = cbox\n",
    "        if cconf < 0.85: continue  # ✅ 0.9 이상일 때만 처리\n",
    "        cx1, cy1, cx2, cy2 = map(int, [cx1, cy1, cx2, cy2])\n",
    "        cv2.rectangle(frame, (cx1, cy1), (cx2, cy2), (255, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Crosswalk ({cconf:.2f})\", (cx1, cy1 - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "\n",
    "\n",
    "\n",
    "    # 3. 사용자 커스텀 YOLO 모델의 모든 객체 감지\n",
    "    lamp_results = lamp_yolo(frame)[0]\n",
    "    for lbox in lamp_results.boxes.data.tolist():\n",
    "        lx1, ly1, lx2, ly2, lconf, lcls = lbox\n",
    "        if lconf < 0.5:\n",
    "            continue\n",
    "        lx1, ly1, lx2, ly2 = map(int, [lx1, ly1, lx2, ly2])\n",
    "        class_id = int(lcls)\n",
    "        class_name = lamp_yolo.model.names[class_id] if class_id in lamp_yolo.model.names else f\"Class {class_id}\"\n",
    "        cv2.rectangle(frame, (lx1, ly1), (lx2, ly2), (255, 0, 255), 2)\n",
    "        cv2.putText(frame, f\"{class_name} ({lconf:.2f})\", (lx1, ly1 - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)\n",
    "        \n",
    "    # 4. 자전거 감지 (COCO 모델 사용)\n",
    "    # 4. 자전거 감지 (사용자 커스텀 모델 사용, 클래스 번호 1번만 감지)\n",
    "    bike_yolo = YOLO(\"/data/LEE/bike-and-braille-3/bicycle_train/weights/best.pt\")\n",
    "\n",
    "    bike_results = bike_yolo(frame)[0]  # ✅ bike_yolo는 사용자 학습된 YOLO 객체여야 함\n",
    "\n",
    "    for bbox in bike_results.boxes.data.tolist():\n",
    "        bx1, by1, bx2, by2, bconf, bcls = bbox\n",
    "        if int(bcls) != 1:  # ✅ 클래스 번호가 1번만 감지\n",
    "            continue\n",
    "        if bconf < 0.5:\n",
    "            continue\n",
    "        bx1, by1, bx2, by2 = map(int, [bx1, by1, bx2, by2])\n",
    "        cv2.rectangle(frame, (bx1, by1), (bx2, by2), (0, 255, 255), 2)\n",
    "        cv2.putText(frame, f\"Custom Bicycle ({bconf:.2f})\", (bx1, by1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "\n",
    "\n",
    "    # 프레임 저장\n",
    "    out.write(frame)\n",
    "\n",
    "# ✅ 마무리\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"✅ 최종 결과 저장 완료: 2_final.mp4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be664711",
   "metadata": {},
   "source": [
    "# 버스 번호 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c644b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yolov8_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'weights_only' is an invalid keyword argument for load()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m out \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# **3️⃣ EasyOCR 리더 생성**\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[43measyocr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mko\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# **4️⃣ YOLO를 사용하여 객체 탐지 및 OCR 적용**\u001b[39;00m\n\u001b[1;32m     30\u001b[0m target_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfront_num\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mback_num\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mside_num\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# ✅ bus 제외\u001b[39;00m\n",
      "File \u001b[0;32m/data/yolov8_env/lib/python3.8/site-packages/easyocr/easyocr.py:214\u001b[0m, in \u001b[0;36mReader.__init__\u001b[0;34m(self, lang_list, gpu, model_storage_directory, user_network_directory, detect_network, recog_network, download_enabled, detector, recognizer, verbose, quantize, cudnn_benchmark)\u001b[0m\n\u001b[1;32m    211\u001b[0m     dict_list[lang] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BASE_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdict\u001b[39m\u001b[38;5;124m'\u001b[39m, lang \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detector:\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitDetector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetector_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recognizer:\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recog_network \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneration1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/data/yolov8_env/lib/python3.8/site-packages/easyocr/easyocr.py:271\u001b[0m, in \u001b[0;36mReader.initDetector\u001b[0;34m(self, detector_path)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minitDetector\u001b[39m(\u001b[38;5;28mself\u001b[39m, detector_path):\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetector_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mquantize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcudnn_benchmark\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn_benchmark\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/yolov8_env/lib/python3.8/site-packages/easyocr/detection.py:85\u001b[0m, in \u001b[0;36mget_detector\u001b[0;34m(trained_model, device, quantize, cudnn_benchmark)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     net\u001b[38;5;241m.\u001b[39mload_state_dict(copyStateDict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m))\n\u001b[1;32m     86\u001b[0m     net \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mDataParallel(net)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     87\u001b[0m     cudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m cudnn_benchmark\n",
      "File \u001b[0;32m/data/yolov8_env/lib/python3.8/site-packages/ultralytics/utils/patches.py:86\u001b[0m, in \u001b[0;36mtorch_load\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     84\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_torch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/yolov8_env/lib/python3.8/site-packages/torch/serialization.py:713\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[1;32m    712\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/yolov8_env/lib/python3.8/site-packages/torch/serialization.py:920\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived object of type \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctionality.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 920\u001b[0m magic_number \u001b[38;5;241m=\u001b[39m \u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic_number \u001b[38;5;241m!=\u001b[39m MAGIC_NUMBER:\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid magic number; corrupt file?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'weights_only' is an invalid keyword argument for load()"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import re  # 숫자 검출을 위한 정규 표현식 사용\n",
    "\n",
    "# **1️⃣ YOLO 모델 로드**\n",
    "model_path = \"/data/BUS/trained_model.pt\"  # YOLO 모델 파일 경로\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# **2️⃣ 영상 로드 및 저장 준비**\n",
    "video_path = \"/data/LEE/버스2.mp4\"  # 입력 비디오 경로\n",
    "output_video_path = \"/data/LEE/버스2_final.mp4\"  # 출력 비디오 경로\n",
    "cap = cv2.VideoCapture(video_path)  # 비디오 캡처 객체\n",
    "\n",
    "# 비디오 속성 가져오기\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# 비디오 저장을 위한 VideoWriter 객체 설정\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # 코덱 설정\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# **3️⃣ EasyOCR 리더 생성**\n",
    "reader = easyocr.Reader([\"ko\", \"en\"], gpu=False)  # GPU 사용 안 함\n",
    "\n",
    "# **4️⃣ YOLO를 사용하여 객체 탐지 및 OCR 적용**\n",
    "target_classes = {\"front_num\", \"back_num\", \"side_num\"}  # ✅ bus 제외\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame)\n",
    "\n",
    "    cropped_images = {}\n",
    "    expand_ratio = 0.1  # 🔹 바운딩 박스를 확장할 비율 (10%)\n",
    "\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # 검출된 박스 좌표\n",
    "            label = r.names[int(box.cls[0])]  # 객체 이름\n",
    "\n",
    "            if label in target_classes:  # ✅ 번호판 3개만 처리\n",
    "                # 🔹 바운딩 박스 확장\n",
    "                width, height = x2 - x1, y2 - y1\n",
    "                x1 = max(0, x1 - int(width * expand_ratio))\n",
    "                y1 = max(0, y1 - int(height * expand_ratio))\n",
    "                x2 = min(frame.shape[1], x2 + int(width * expand_ratio))\n",
    "                y2 = min(frame.shape[0], y2 + int(height * expand_ratio))\n",
    "\n",
    "                cropped_img = frame[y1:y2, x1:x2]\n",
    "                cropped_images[label] = cropped_img  # 라벨별 이미지 저장\n",
    "\n",
    "    bus_number = \"N/A (모든 번호 인식 실패)\"\n",
    "    bus_number_source = None  # 어디서 인식했는지 저장\n",
    "    processed_images = {}\n",
    "\n",
    "    for label, cropped_img in cropped_images.items():\n",
    "        # 🔹 1차 OCR을 위한 이미지 전처리 (이진화)\n",
    "        gray = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # 🔹 밝은 숫자 강조 (THRESH_BINARY)\n",
    "        lower_white = 200\n",
    "        upper_white = 255\n",
    "        _, binary = cv2.threshold(gray, lower_white, upper_white, cv2.THRESH_BINARY)\n",
    "\n",
    "        # 🔹 OCR 실행 (이진화된 이미지)\n",
    "        ocr_result = reader.readtext(binary, detail=0)\n",
    "        extracted_text = \" \".join(ocr_result) if ocr_result else \"N/A\"\n",
    "\n",
    "        # 🔹 OCR 결과가 숫자를 포함하는지 확인\n",
    "        if re.search(r\"\\d\", extracted_text):  # 숫자가 하나라도 포함된 경우\n",
    "            bus_number = extracted_text  # 버스 번호 확정\n",
    "            bus_number_source = f\"{label} (이진화된 이미지)\"\n",
    "            processed_images = {label: binary}  # 해당 이미지만 출력\n",
    "            break  # 첫 번째로 감지된 숫자로 확정 후 반복 종료\n",
    "\n",
    "    # **5️⃣ 영상에 OCR 결과 표시**\n",
    "    for label, cropped_img in cropped_images.items():\n",
    "        if label in processed_images:\n",
    "            # OCR을 적용한 이미지에 텍스트 추가\n",
    "            cv2.putText(frame, bus_number, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # **6️⃣ 영상 저장**\n",
    "    out.write(frame)\n",
    "\n",
    "# **7️⃣ 영상 처리 종료 및 저장**\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"🎯 최종 버스 번호: {bus_number} (출처: {bus_number_source})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
